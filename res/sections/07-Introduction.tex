 % This is just a draft, nothing suitable for the final product: sources are in
 % form of a todo
 
 % --- INTRODUCTION ---
\chapter{Introduction}
\label{chap:intro}

 Through the history of internet, many factors changed and new innovations came,
 but at the end of the day a foundamental key remained: connection performances
 are, indeed, what the users really want.\todo{Idea: talk about how TCP/IP
   performes quite well in wired connections, while in wireless one, such as
   wireless/satellite, sucks ass}
With the arrival of mobile connectivity, wireless networks started to have an 
important role in everyone's life. In this context network efficiency plays 
an important role with the development of new connectivity standards (e.g 2G, 
3G, LTE) and the creation of common communication protocols ad-hoc versions 
(i.e. TCP versions specialized for exploit the characteristic of wireless 
networks). It is for this reason that, beside improved radio communications, 
backend infrastructure began to be refined too. During their travel to the 
destination packets are elaborated, compressed and processed in order to make 
their transmission as fast as possible.
On top of that, mobile traffic is continuously surging every year, with the 
backbones having more and more data to deliver, making in-hardware backbone 
solutions less efficent. Their time-to-deploy, in fact, is very high compared 
to the requirements of the network. With this trend, in-hardware solutions 
will not be able to keep up. Is with this considerations that software a 
software approach is being proposed to become the new way to deploy network 
components. While less efficent, they are faster to bring them up, offering an 
unprecedented flexibility\todo{CITE: SDN/NFV-Based Mobile Packet Core Network 
Architectures: A Survey}.
 Furthermore, new virtualization technologies such as Cloud computing and Docker
 are becoming more and more mature for being employed in large-scale production
 environments, where new frameworks, called orchestrators (e.g. Kubernetes,
 Docker Swarm), allow to easily manage the application lifecyle, i.e.
 deployment, scale up/down and finally, removal.

\section{The upcoming connectivity standard: 5G}
The continuous innovation in the mobile network connectivity is leading to the
creation of a new standard, the 5G, which is estimated to arrive to the market
constumer in 2020\todo{CITE}. Lead by the Next Generation Mobile Network (NGMN)
alliace, a group composed by the major players in the field of mobile
connectivity, the 5G aims to offer at the end-user a new way to browse the web,
download and watch interactive content. Relatively to 4G, 5G points to have data
rates $10$ times better, with $10$ times smaller end-to-end latency and an
increased connection densisty by $100$ times\todo{CITE}.

\begin{table}[t]
\centering
\resizebox{\textwidth}{!}{%
  \begin{tabular}{p{4cm}|p{5,5cm}|p{5,5cm}}
\textbf{Attribute}                                                    & \textbf{LTE capability}                                                                                                                                     & \textbf{Improvement needed to meet NGMN requirements}                 \\ \hline
\textbf{Data rate (per user)}                                         & Up to 100 Mb/s on average Peaks of 600 Mb/s (Cat 11/12).                                                                                                    & 10X expected on average and peak rates and 100X expected on cell edge \\
\textbf{End-to-end latency}                                           & 10 ms for two-way RAN (pre-scheduled). Typically, up to 50 ms end-to-end if other factors are considered (e.g., transmission, CN, internet, proxy servers). & 10X (smaller)                                                         \\
\textbf{Mobility}                                                     & Functional up to 350 km/h (for certain bands up to 500 km/h). No support for civil aviation.                                                                & 1.5X                                                                  \\
\textbf{\begin{tabular}[c]{@{}l@{}}Connection\\ density\end{tabular}} & Typically $\sim$2,000 active users/km2.                                                                                                                     & 100X                                                                 
\end{tabular}%
}
\caption[5G improvement over LTE]{An extract from the official 5G white paper illustating the improvements of 5G relatively to LTE connections.}
\label{chap:intro:table:ltevs5g}
\end{table}

Part of the new requirements can be satisfied using a large radio spectrum with
higher frequencies. The utilization of higher frequencies, though, mean that the
radio signals can be easly disrupted by physical objects, like buildings and
many geographical elements (such as hills and mountains), clashing with the
expectation of an ever-reachable connectivity. It is here where virtualization
plays an important role. In fact, the re-design of some network components today
existing via hardware can transform a monolitic networking approach to a modular
one, exploting the flexibility that Virtual Network Functions (VNFs)\todo{CITE
  VNF-P: A Model for Efficient Placement of Virtualized Network Functions} can
offer thanks to virtualization, closing the gap to the use-case fullfilment
defined by the NGMS alliance\todo{CITE: NGMN View on 5G architecture}.

\subsection{5G architecture}

With the constraints placed on the requirements formulated by the NGMN alliance,
5G envisage a multi-layered architecture, based on three main layers:\todo{CITE:
  NGMN View on 5G architecture}
\begin{itemize}
\item \textbf{infrastructure resouce layer}: physical resources that are exposed
  via a virtualized interface, and that can be monitored using specific APIs
\item \textbf{business enablement layer}: where a library of functions and
  deployment is contained, and its configuration is accessible via APIs
\item \textbf{business application layer}: layer that contains specific
  applications and services of the operator
\end{itemize}

\todo{Add three-layer image here?}

\subsubsection{Network slicing}
The role of a ``network slice'' in a 5G architecture is to specificatly handle a
Control-place of a praticular service (e.g. smartphones traffic, autonomous
driving, massive IoT), deploying resources in a manner that assure the required
latency, security and reliability. While some legacy of very peculiar services
could require specific hardware, the common resources between services could be
shared in a virtualized way, providing auto-scaling capabilities in services
that are under heavy network pressure.

\section{The VIBES project}
 
 This thesis is part of the VIBES project\todo{Talk about VIBES project, add
   some reference, explain what it is.}, where the necessity for better TCP/IP
 transmission through satellite connections is the main requirement. To reach
 this goal, the project specifications suggest to exploit the 5G incoming
 technology and use the NFV-MANO architecture to perform first packets
 elaboration and performance improvment and finally TCP/IP satellite chunk
 optimization with the Performance Enhancing Proxy (PEP). The VIBES project
 proposed five technical requirements:
\begin{enumerate}
 \item Analysis of the applicability of current and new Internet protocols in
   the proposed VNF-PEP architecture
 \item Implementation of a VNF-PEP prototype
 \item Building of a PoC test platform
 \item VNF-PEP validation and performance tests on 5G use-cases
 \item Demonstration testbed management
\end{enumerate}

\subsection{VNF-PEP architecture and internet protocols}

The analysis of this topic revealed to be trivial: since internet has many
different protocols that would become infeasible to support all of them at the
same time, packet incapsulation present itself as the only faseable solution:
every packet incoming in the VNFs has already been encapsulated by the MANO,
\todo{Not sure about this, please give it a check - Not sure but I think that it
  is not part of the MANO the encapsulation of the packets. Also I think that
  the main purpose of UDP encapsulation is not to hide the protocol used on the
  edges but 1) usa a ``quick protocol to exchange data among VNFs and 2) we are
  hiding the path not the protocol itself. As we were discussing, we are
  creating some sort of proxy, so the aim will be the same even if we support a
  plethora of protocols.''} making the whole architecture indipendent from the
protocol a particolar flux of data uses. To achieve this, TUN/TAP interfaces 
were used to deploy a tunnel between VNFs, allowing them to pass packets 
encapsulated in UDP ones.

\subsection{VNF-PEP prototype}

Since our goal shifted into creating a MANO testbed, our prototype doesn't
include PEP. The VNF architecture was shaped following the container
orchestrator we decided to use: Kubernetes.

\subsubsection{About Kubernetes}

As already introduced before, Kubernetes is an open source software framework
specialized in container management and orchestration. Developed by Google in
??\todo{Find out the actual date} and written in Go, it allows different
machines (called nodes from now on) to create an abstraction layer and to form a
cluster where is possible to run Docker containers without brothering about
hardware constraints. Nodes can have specific roles and specialization, all of
them managed by one or many master nodes, that actually manage the
orchestration. On top of that, Kubernetes is virtualization-agnostic, meaning
that it offers the possibility to change the virtualization software in use
(i.e. from Container-based technology to Virtual machine software).
\begin{figure}[h]
 \centering \includegraphics[scale=0.35]{kubernetes_logo}
 \caption{Kubernetes Logo}
 \label{chap:intro:img:k8s_logo}
\end{figure}


\subsubsection{About Docker}

In recent years, with the new hardware capabilities and the recent development
of in-kernel virtualization systems (such as Hyper-V) this technology begin to
be adopted. Virtualization allows to run different systems on the same machine,
making them completely isolated and then more resilient to failures. The back of
the medal, though, is that virtual machines require large amount of resources,
especially memory, because solutions like copy-and-write of in-memory pages are
not viable anymore (since the kernel gets duplicated too), leading to
duplication of loaded libraries and assets in the memory of the host. For large
deployment containing only simple services (e.g. a backend application serving a
website or a database) this ends up in a waste of resources. \todo{Talk about
  lxc containers and how Docker solved magically the problem.} It's here that,
in ??\todo{Find Docker date of birth}, Docker was created, basing its solution
on an already existing product: Linux Container (LXC). From this framework,
Docker built an entire ecosystem, consisting in a client/server model giving the
possibility for users to simply launch, scale and delete containers (locally or
remotely with Docker-machine), a repository system where images, a layer-based
``core'' where containers start running from when they are launched, can be
stored and tagged in a sort of version control system. Finally, another couple
of solutions, called Docker-compose, and Docker Swarm have the purpose to,
respectively, orchestrate containers in a single or a clustered system.
\begin{figure}[t]
 \centering \includegraphics[scale=0.7]{docker_logo}
 \caption{Official Docker logo}
 \label{chap:intro:img:docker_logo}
\end{figure}


\paragraph{Docker Swarm} Introduced in ??\todo{Find Docker Swarm date of
birth}, Docker Swarm allows multiple Docker nodes to cluster together and be
seen as one logical unit. This layer completely makes the underlying
infrastructure transparent: data management, as network one, are totaly managed
by Docker. Recently, Docker-compose support has been introduced, making this
one-node tool available for clustered systems. At the end of the day, on one
hand Docker Swarm provides an easy way to set up a cluster system with all the
tools configured out-of-the-box, without the necessity to set networking
configurations or installing ad-hoc storage solutions. On the other hand,
though, it doesn't have all the personalization options that Kuberentes offers,
thus making the product less flexible. This foundamental characteristic,
although, makes the two solutions have different use cases leading to different
market needs. \todo{Add Docker Swarm}

\paragraph{Docker-compose} As briefly discussed above, Docker-compose is a tool
that allows services orchestration. It automates most of the tasks that should
be performed by hand when launching one or multiple docker containers. It's
particulary useful when more continers have to interact together,
because\todo{Write down docker-compose functionalities and describe the product
  a little bit} all the services rules are described in a simple YAML file. With
the birth of Docker Swarm, work has started to port this tool to the Swarm
framework. At the time of this writing, the procedure to port a Docker-compose
configuration in Docker Swarm is still not completely transparent, and it
requires a sort of compilation, where Docker-compose bundles all the necessaries
resources into a binary file that Docker Swarm will use to allocate the
necessary resources.

\vspace{0.5cm}

Starting with the first step of creating a MANO able to process incoming data
packets through VNF functions, we encountered that many networking tools already
present in the market required some tweaking and some integrations, shifting our
goal to create a complete European Telecommunications Standards Institutes
(ETSI) Management and orchestrator (MANO) testbed instead, following the
specifications suggested in the RFC 7665, thus implementing only the first three
requisites, without digging in the satellite data flow optimization. In
particular, we discovered how, these tools, were suitable to create ETSI MANO
and VNFs using virtual machine or exploiting cloud tecnhologies, while they were
not designed with enough flexibility to integrate with Docker. In the next
chapter we are going to take a deep analysis of the cited technologies, in order
to provide to the reader enough context to be able to understand our design
choices we are going to describe later.


\noindent With this in mind, we performed a requirements analysis described in
the next chapter.\todo{This should be put at the end of the introduction.}
